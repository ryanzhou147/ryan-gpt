import torch
import math
import triton
import triton.language as tl
torch.cuda.init()

class FlashAttentionFunctionPyTorch(torch.autograd.Function):

    @staticmethod
    def forward(ctx, Q, K, V, is_causal=False):
        _, Nq, d = Q.shape
        _, Nk, _ = K.shape
        
        scale = 1.0 / math.sqrt(d)
        
        Bq, Bk = 16, 16
        Tq = math.ceil(Nq / Bq)
        Tk = math.ceil(Nk / Bk)
        
        O = torch.zeros_like(Q)  # (batch, Nq, d)
        L = torch.zeros(Q.shape[0], Nq, device=Q.device, dtype=Q.dtype)  # (batch, Nq)
        
        # Loop over batch
        for b in range(Q.shape[0]):
            Qb = Q[b]  # (Nq, d)
            Kb = K[b]  # (Nk, d)
            Vb = V[b]  # (Nk, d)
            
            for i in range(Tq):
                i_start, i_end = i * Bq, min((i + 1) * Bq, Nq)
                
                Qi = Qb[i_start:i_end]  # (Bq, d)
                Oi = torch.zeros_like(Qi)
                li = torch.zeros(Qi.shape[0], device=Q.device, dtype=Q.dtype)
                mi = torch.full((Qi.shape[0],), float('-inf'), device=Q.device, dtype=Q.dtype)
                
                for j in range(Tk):
                    j_start, j_end = j * Bk, min((j + 1) * Bk, Nk)
                    
                    Kj = Kb[j_start:j_end]  # (Bk, d)
                    Vj = Vb[j_start:j_end]  # (Bk, d)
                    
                    # S_ij = Qi @ K_j^T / sqrt(d)
                    Sij = (Qi @ Kj.T) * scale  # (Bq, Bk)

                    if is_causal:
                        q_idx = torch.arange(i_start, i_end, device=Q.device).unsqueeze(-1)
                        k_idx = torch.arange(j_start, j_end, device=Q.device).unsqueeze(0)
                        Sij = Sij.masked_fill(q_idx < k_idx, -1e6)
                    
                    # m_new = max(m_old, rowmax(S_ij))
                    mi_new = torch.maximum(mi, Sij.max(dim=-1).values)
                    
                    # P_ij = exp(S_ij - m_new)
                    Pij = torch.exp(Sij - mi_new.unsqueeze(-1))
                    
                    # alpha = exp(m_old - m_new)
                    alpha = torch.exp(mi - mi_new)
                    
                    # l_new = alpha * l_old + rowsum(P_ij)
                    li = alpha * li + Pij.sum(dim=-1)
                    
                    # O_new = alpha * O_old + P_ij @ V_j
                    Oi = alpha.unsqueeze(-1) * Oi + Pij @ Vj
                    
                    mi = mi_new
                
                # Final normalization
                O[b, i_start:i_end] = Oi / li.unsqueeze(-1)
                L[b, i_start:i_end] = mi + torch.log(li)
        
        ctx.save_for_backward(Q, K, V, O, L)
        return O
    
    @staticmethod
    def backward(ctx, grad_output):
        Q, K, V, O, L = ctx.saved_tensors
        
        batch, Nq, d = Q.shape
        _, Nk, _ = K.shape
        scale = 1.0 / math.sqrt(d)
        
        Bq, Bk = 16, 16
        Tq = math.ceil(Nq / Bq)
        Tk = math.ceil(Nk / Bk)
        
        # Initialize gradients
        dQ = torch.zeros_like(Q)
        dK = torch.zeros_like(K)
        dV = torch.zeros_like(V)
        
        # Precompute Di = rowsum(dO * O) for all positions
        Di = torch.sum(grad_output * O, dim=-1)  # (batch, Nq)
        
        for b in range(batch):
            Qb = Q[b]      # (Nq, d)
            Kb = K[b]      # (Nk, d)
            Vb = V[b]      # (Nk, d)
            Ob = O[b]      # (Nq, d)
            Lb = L[b]      # (Nq,)
            dOb = grad_output[b]  # (Nq, d)
            Dib = Di[b]    # (Nq,)
            
            for i in range(Tq):
                i_start, i_end = i * Bq, min((i + 1) * Bq, Nq)
                
                Qi = Qb[i_start:i_end]      # (Bq, d)
                Oi = Ob[i_start:i_end]      # (Bq, d)
                Li = Lb[i_start:i_end]      # (Bq,)
                dOi = dOb[i_start:i_end]    # (Bq, d)
                Dii = Dib[i_start:i_end]    # (Bq,)
                
                dQi = torch.zeros_like(Qi)  # Accumulate dQ for this tile
                
                for j in range(Tk):
                    j_start, j_end = j * Bk, min((j + 1) * Bk, Nk)
                    
                    Kj = Kb[j_start:j_end]  # (Bk, d)
                    Vj = Vb[j_start:j_end]  # (Bk, d)
                    
                    # Recompute attention scores for this tile
                    Sij = (Qi @ Kj.T) * scale  # (Bq, Bk)
                    
                    # Recompute P using saved logsumexp
                    Pij = torch.exp(Sij - Li.unsqueeze(-1))  # (Bq, Bk)
                    
                    # dV += P^T @ dO
                    dV[b, j_start:j_end] += Pij.T @ dOi  # (Bk, d)
                    
                    # dP = dO @ V^T
                    dPij = dOi @ Vj.T  # (Bq, Bk)
                    
                    # dS = P * (dP - Di)
                    dSij = Pij * (dPij - Dii.unsqueeze(-1))  # (Bq, Bk)
                    
                    # dQ += dS @ K * scale
                    dQi += (dSij @ Kj) * scale  # (Bq, d)
                    
                    # dK += dS^T @ Q * scale
                    dK[b, j_start:j_end] += (dSij.T @ Qi) * scale  # (Bk, d)
                
                dQ[b, i_start:i_end] = dQi
        
        return dQ, dK, dV, None

@triton.jit
def flash_fwd_kernel(
    Q_ptr, K_ptr, V_ptr,
    O_ptr, L_ptr,
    stride_qb, stride_qq, stride_qd,
    stride_kb, stride_kk, stride_kd,
    stride_vb, stride_vk, stride_vd,
    stride_ob, stride_oq, stride_od,
    stride_lb, stride_lq,
    N_QUERIES, N_KEYS,
    scale,
    IS_CAUSAL: tl.constexpr,
    D: tl.constexpr,
    Q_TILE_SIZE: tl.constexpr,
    K_TILE_SIZE: tl.constexpr,
):
    query_tile_idx = tl.program_id(0)
    batch_idx = tl.program_id(1)
    
    # Block pointers
    Q_block_ptr = tl.make_block_ptr(
        Q_ptr + batch_idx * stride_qb,
        shape=(N_QUERIES, D), strides=(stride_qq, stride_qd),
        offsets=(query_tile_idx * Q_TILE_SIZE, 0),
        block_shape=(Q_TILE_SIZE, D), order=(1, 0),
    )
    K_block_ptr = tl.make_block_ptr(
        K_ptr + batch_idx * stride_kb,
        shape=(N_KEYS, D), strides=(stride_kk, stride_kd),
        offsets=(0, 0),
        block_shape=(K_TILE_SIZE, D), order=(1, 0),
    )
    V_block_ptr = tl.make_block_ptr(
        V_ptr + batch_idx * stride_vb,
        shape=(N_KEYS, D), strides=(stride_vk, stride_vd),
        offsets=(0, 0),
        block_shape=(K_TILE_SIZE, D), order=(1, 0),
    )
    O_block_ptr = tl.make_block_ptr(
        O_ptr + batch_idx * stride_ob,
        shape=(N_QUERIES, D), strides=(stride_oq, stride_od),
        offsets=(query_tile_idx * Q_TILE_SIZE, 0),
        block_shape=(Q_TILE_SIZE, D), order=(1, 0),
    )
    L_block_ptr = tl.make_block_ptr(
        L_ptr + batch_idx * stride_lb,
        shape=(N_QUERIES,), strides=(stride_lq,),
        offsets=(query_tile_idx * Q_TILE_SIZE,),
        block_shape=(Q_TILE_SIZE,), order=(0,),
    )
    
    # Load Q once
    Qi = tl.load(Q_block_ptr)
    
    # On-chip accumulators (float32 for precision)
    Oi = tl.zeros((Q_TILE_SIZE, D), dtype=tl.float32)
    li = tl.zeros((Q_TILE_SIZE,), dtype=tl.float32)
    mi = tl.full((Q_TILE_SIZE,), float('-inf'), dtype=tl.float32)
    
    # Loop over key tiles
    for j in range(tl.cdiv(N_KEYS, K_TILE_SIZE)):
        Kj = tl.load(K_block_ptr)
        Vj = tl.load(V_block_ptr)
        
        # Attention scores
        Sij = tl.dot(Qi, tl.trans(Kj)) * scale
        
        # Causal mask
        if IS_CAUSAL:
            q_idx = query_tile_idx * Q_TILE_SIZE + tl.arange(0, Q_TILE_SIZE)
            k_idx = j * K_TILE_SIZE + tl.arange(0, K_TILE_SIZE)
            Sij = tl.where(q_idx[:, None] >= k_idx[None, :], Sij, -1e6)
        
        # Online softmax
        mi_new = tl.maximum(mi, tl.max(Sij, axis=1))
        Pij = tl.exp(Sij - mi_new[:, None])
        alpha = tl.exp(mi - mi_new)
        li = alpha * li + tl.sum(Pij, axis=1)
        Oi = alpha[:, None] * Oi + tl.dot(Pij.to(Vj.dtype), Vj)
        mi = mi_new
        
        # Advance pointers
        K_block_ptr = tl.advance(K_block_ptr, (K_TILE_SIZE, 0))
        V_block_ptr = tl.advance(V_block_ptr, (K_TILE_SIZE, 0))
    
    # Normalize and store
    Oi = Oi / li[:, None]
    tl.store(O_block_ptr, Oi.to(O_block_ptr.type.element_ty))
    tl.store(L_block_ptr, (mi + tl.log(li)).to(L_block_ptr.type.element_ty))


@triton.jit
def flash_bwd_kernel(
    Q_ptr, K_ptr, V_ptr, O_ptr, L_ptr,
    dO_ptr, dK_ptr, dV_ptr,
    stride_qb, stride_qq, stride_qd,
    stride_kb, stride_kk, stride_kd,
    stride_vb, stride_vk, stride_vd,
    stride_ob, stride_oq, stride_od,
    stride_lb, stride_lq,
    stride_dob, stride_doq, stride_dod,
    stride_dkb, stride_dkk, stride_dkd,
    stride_dvb, stride_dvk, stride_dvd,
    N_QUERIES, N_KEYS,
    scale,
    IS_CAUSAL: tl.constexpr,
    D: tl.constexpr,
    Q_TILE_SIZE: tl.constexpr,
    K_TILE_SIZE: tl.constexpr,
):
    """Compute dK and dV."""
    kv_tile_idx = tl.program_id(0)
    batch_idx = tl.program_id(1)
    
    kv_start = kv_tile_idx * K_TILE_SIZE
    
    # Load K, V for this tile
    k_offsets = kv_start + tl.arange(0, K_TILE_SIZE)
    d_offsets = tl.arange(0, D)
    
    kv_mask = k_offsets[:, None] < N_KEYS
    
    K_ptrs = K_ptr + batch_idx * stride_kb + k_offsets[:, None] * stride_kk + d_offsets[None, :] * stride_kd
    V_ptrs = V_ptr + batch_idx * stride_vb + k_offsets[:, None] * stride_vk + d_offsets[None, :] * stride_vd
    
    Kj = tl.load(K_ptrs, mask=kv_mask, other=0.0)
    Vj = tl.load(V_ptrs, mask=kv_mask, other=0.0)
    
    # Accumulators
    dKj = tl.zeros((K_TILE_SIZE, D), dtype=tl.float32)
    dVj = tl.zeros((K_TILE_SIZE, D), dtype=tl.float32)
    
    # Iterate over Q tiles
    num_q_tiles = tl.cdiv(N_QUERIES, Q_TILE_SIZE)
    
    for i in range(num_q_tiles):
        q_start = i * Q_TILE_SIZE
        q_offsets = q_start + tl.arange(0, Q_TILE_SIZE)
        q_mask = q_offsets[:, None] < N_QUERIES
        
        # Load Q, O, L, dO for this tile
        Q_ptrs = Q_ptr + batch_idx * stride_qb + q_offsets[:, None] * stride_qq + d_offsets[None, :] * stride_qd
        O_ptrs = O_ptr + batch_idx * stride_ob + q_offsets[:, None] * stride_oq + d_offsets[None, :] * stride_od
        L_ptrs = L_ptr + batch_idx * stride_lb + q_offsets * stride_lq
        dO_ptrs = dO_ptr + batch_idx * stride_dob + q_offsets[:, None] * stride_doq + d_offsets[None, :] * stride_dod
        
        Qi = tl.load(Q_ptrs, mask=q_mask, other=0.0)
        Oi = tl.load(O_ptrs, mask=q_mask, other=0.0)
        Li = tl.load(L_ptrs, mask=q_offsets < N_QUERIES, other=0.0)
        dOi = tl.load(dO_ptrs, mask=q_mask, other=0.0)
        
        # Recompute attention scores
        Sij = tl.dot(Qi, tl.trans(Kj)) * scale
        
        # Causal mask
        if IS_CAUSAL:
            causal_mask = q_offsets[:, None] >= k_offsets[None, :]
            Sij = tl.where(causal_mask, Sij, float('-inf'))
        
        # Recompute P from logsumexp
        Pij = tl.exp(Sij - Li[:, None])
        
        # Di = rowsum(dO * O)
        Di = tl.sum(dOi * Oi, axis=1)
        
        # dV += P^T @ dO
        dVj += tl.dot(tl.trans(Pij.to(dOi.dtype)), dOi)
        
        # dP = dO @ V^T
        dPij = tl.dot(dOi, tl.trans(Vj))
        
        # dS = P * (dP - Di)
        dSij = Pij * (dPij - Di[:, None])
        
        # dK += dS^T @ Q * scale
        dKj += tl.dot(tl.trans(dSij.to(Qi.dtype)), Qi) * scale
    
    # Store dK, dV
    dK_ptrs = dK_ptr + batch_idx * stride_dkb + k_offsets[:, None] * stride_dkk + d_offsets[None, :] * stride_dkd
    dV_ptrs = dV_ptr + batch_idx * stride_dvb + k_offsets[:, None] * stride_dvk + d_offsets[None, :] * stride_dvd
    
    tl.store(dK_ptrs, dKj.to(K_ptr.dtype.element_ty), mask=kv_mask)
    tl.store(dV_ptrs, dVj.to(V_ptr.dtype.element_ty), mask=kv_mask)


@triton.jit
def flash_bwd_dq_kernel(
    Q_ptr, K_ptr, V_ptr, O_ptr, L_ptr,
    dO_ptr, dQ_ptr,
    stride_qb, stride_qq, stride_qd,
    stride_kb, stride_kk, stride_kd,
    stride_vb, stride_vk, stride_vd,
    stride_ob, stride_oq, stride_od,
    stride_lb, stride_lq,
    stride_dob, stride_doq, stride_dod,
    stride_dqb, stride_dqq, stride_dqd,
    N_QUERIES, N_KEYS,
    scale,
    IS_CAUSAL: tl.constexpr,
    D: tl.constexpr,
    Q_TILE_SIZE: tl.constexpr,
    K_TILE_SIZE: tl.constexpr,
):
    """Compute dQ."""
    q_tile_idx = tl.program_id(0)
    batch_idx = tl.program_id(1)
    
    q_start = q_tile_idx * Q_TILE_SIZE
    q_offsets = q_start + tl.arange(0, Q_TILE_SIZE)
    d_offsets = tl.arange(0, D)
    q_mask = q_offsets[:, None] < N_QUERIES
    
    # Load Q, O, L, dO
    Q_ptrs = Q_ptr + batch_idx * stride_qb + q_offsets[:, None] * stride_qq + d_offsets[None, :] * stride_qd
    O_ptrs = O_ptr + batch_idx * stride_ob + q_offsets[:, None] * stride_oq + d_offsets[None, :] * stride_od
    L_ptrs = L_ptr + batch_idx * stride_lb + q_offsets * stride_lq
    dO_ptrs = dO_ptr + batch_idx * stride_dob + q_offsets[:, None] * stride_doq + d_offsets[None, :] * stride_dod
    
    Qi = tl.load(Q_ptrs, mask=q_mask, other=0.0)
    Oi = tl.load(O_ptrs, mask=q_mask, other=0.0)
    Li = tl.load(L_ptrs, mask=q_offsets < N_QUERIES, other=0.0)
    dOi = tl.load(dO_ptrs, mask=q_mask, other=0.0)
    
    # Di = rowsum(dO * O)
    Di = tl.sum(dOi * Oi, axis=1)
    
    # Accumulator
    dQi = tl.zeros((Q_TILE_SIZE, D), dtype=tl.float32)
    
    # Iterate over K/V tiles
    num_kv_tiles = tl.cdiv(N_KEYS, K_TILE_SIZE)
    
    for j in range(num_kv_tiles):
        k_start = j * K_TILE_SIZE
        k_offsets = k_start + tl.arange(0, K_TILE_SIZE)
        kv_mask = k_offsets[:, None] < N_KEYS
        
        K_ptrs = K_ptr + batch_idx * stride_kb + k_offsets[:, None] * stride_kk + d_offsets[None, :] * stride_kd
        V_ptrs = V_ptr + batch_idx * stride_vb + k_offsets[:, None] * stride_vk + d_offsets[None, :] * stride_vd
        
        Kj = tl.load(K_ptrs, mask=kv_mask, other=0.0)
        Vj = tl.load(V_ptrs, mask=kv_mask, other=0.0)
        
        # Recompute attention scores
        Sij = tl.dot(Qi, tl.trans(Kj)) * scale
        
        # Causal mask
        if IS_CAUSAL:
            causal_mask = q_offsets[:, None] >= k_offsets[None, :]
            Sij = tl.where(causal_mask, Sij, float('-inf'))
        
        # Recompute P
        Pij = tl.exp(Sij - Li[:, None])
        
        # dP = dO @ V^T
        dPij = tl.dot(dOi, tl.trans(Vj))
        
        # dS = P * (dP - Di)
        dSij = Pij * (dPij - Di[:, None])
        
        # dQ += dS @ K * scale
        dQi += tl.dot(dSij.to(Kj.dtype), Kj) * scale
    
    # Store dQ
    dQ_ptrs = dQ_ptr + batch_idx * stride_dqb + q_offsets[:, None] * stride_dqq + d_offsets[None, :] * stride_dqd
    tl.store(dQ_ptrs, dQi.to(Q_ptr.dtype.element_ty), mask=q_mask)


class FlashAttentionFunctionTriton(torch.autograd.Function):
    
    Q_TILE_SIZE = 32
    K_TILE_SIZE = 32

    @staticmethod
    def forward(ctx, Q, K, V, is_causal=False):
        batch, Nq, d = Q.shape
        _, Nk, _ = K.s
class FlashAttentionFunctionTriton(torch.autograd.Function):

    @staticmethod
    def get_tile_sizes(d):
        """Choose tile sizes based on head dimension to fit in shared memory."""
        if d <= 64:
            return 64, 64
        elif d <= 128:
            return 32, 32
        else:
            return 16, 16

    @staticmethod
    def forward(ctx, Q, K, V, is_causal=False):
        batch, Nq, d = Q.shape
        _, Nk, _ = K.shape
        
        Q_TILE, K_TILE = FlashAttentionFunctionTriton.get_tile_sizes(d)
        
        O = torch.empty_like(Q)
        L = torch.empty(batch, Nq, device=Q.device, dtype=Q.dtype)
        
        grid = (triton.cdiv(Nq, Q_TILE), batch)
        
        flash_fwd_kernel[grid](
            Q, K, V, O, L,
            Q.stride(0), Q.stride(1), Q.stride(2),
            K.stride(0), K.stride(1), K.stride(2),
            V.stride(0), V.stride(1), V.stride(2),
            O.stride(0), O.stride(1), O.stride(2),
            L.stride(0), L.stride(1),
            Nq, Nk,
            1.0 / math.sqrt(d),
            is_causal,
            d,
            Q_TILE,
            K_TILE,
        )
        
        ctx.save_for_backward(Q, K, V, O, L)
        ctx.is_causal = is_causal
        ctx.Q_TILE = Q_TILE
        ctx.K_TILE = K_TILE
        return O

    @staticmethod
    def backward(ctx, grad_output):
        Q, K, V, O, L = ctx.saved_tensors
        is_causal = ctx.is_causal
        Q_TILE = ctx.Q_TILE
        K_TILE = ctx.K_TILE
        
        batch, Nq, d = Q.shape
        _, Nk, _ = K.shape
        
        dQ = torch.empty_like(Q)
        dK = torch.empty_like(K)
        dV = torch.empty_like(V)
        
        grad_output = grad_output.contiguous()
        
        # Compute dK and dV
        grid_kv = (triton.cdiv(Nk, K_TILE), batch)
        flash_bwd_kernel[grid_kv](
            Q, K, V, O, L,
            grad_output, dK, dV,
            Q.stride(0), Q.stride(1), Q.stride(2),
            K.stride(0), K.stride(1), K.stride(2),
            V.stride(0), V.stride(1), V.stride(2),
            O.stride(0), O.stride(1), O.stride(2),
            L.stride(0), L.stride(1),
            grad_output.stride(0), grad_output.stride(1), grad_output.stride(2),
            dK.stride(0), dK.stride(1), dK.stride(2),
            dV.stride(0), dV.stride(1), dV.stride(2),
            Nq, Nk,
            1.0 / math.sqrt(d),
            is_causal,
            d,
            Q_TILE,
            K_TILE,
        )
        
        # Compute dQ
        grid_q = (triton.cdiv(Nq, Q_TILE), batch)
        flash_bwd_dq_kernel[grid_q](
            Q, K, V, O, L,
            grad_output, dQ,
            Q.stride(0), Q.stride(1), Q.stride(2),
            K.stride(0), K.stride(1), K.stride(2),
            V.stride(0), V.stride(1), V.stride(2),
            O.stride(0), O.stride(1), O.stride(2),
            L.stride(0), L.stride(1),
            grad_output.stride(0), grad_output.stride(1), grad_output.stride(2),
            dQ.stride(0), dQ.stride(1), dQ.stride(2),
            Nq, Nk,
            1.0 / math.sqrt(d),
            is_causal,
            d,
            Q_TILE,
            K_TILE,
        )
        
        return dQ, dK, dV, None
    
# Convenience functions
def flash_attention_pytorch(Q, K, V, is_causal=False):
    return FlashAttentionFunctionPyTorch.apply(Q, K, V, is_causal)


def flash_attention_triton(Q, K, V, is_causal=False):
    return FlashAttentionFunctionTriton.apply(Q, K, V, is_causal)


# Test
if __name__ == "__main__":
    torch.manual_seed(42)
    
    batch, seq_len, d = 2, 64, 32
    
    Q = torch.randn(batch, seq_len, d, device='cuda', dtype=torch.float32, requires_grad=True)
    K = torch.randn(batch, seq_len, d, device='cuda', dtype=torch.float32, requires_grad=True)
    V = torch.randn(batch, seq_len, d, device='cuda', dtype=torch.float32, requires_grad=True)
    
    # Reference: standard PyTorch attention
    def standard_attention(Q, K, V, is_causal=False):
        scale = 1.0 / math.sqrt(Q.shape[-1])
        scores = torch.matmul(Q, K.transpose(-2, -1)) * scale
        if is_causal:
            mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1).bool()
            scores = scores.masked_fill(mask, float('-inf'))
        attn = torch.softmax(scores, dim=-1)
        return torch.matmul(attn, V)
    
    # Test against standard attention
    Q_ref = Q.clone().detach().requires_grad_(True)
    K_ref = K.clone().detach().requires_grad_(True)
    V_ref = V.clone().detach().requires_grad_(True)
    
    Q_tr = Q.clone().detach().requires_grad_(True)
    K_tr = K.clone().detach().requires_grad_(True)
    V_tr = V.clone().detach().requires_grad_(True)
    
    out_ref = standard_attention(Q_ref, K_ref, V_ref, is_causal=True)
    out_tr = flash_attention_triton(Q_tr, K_tr, V_tr, is_causal=True)
    
    print("Forward pass (vs standard attention):")
    print(f"  Max diff: {(out_ref - out_tr).abs().max().item():.6f}")
    
    grad_out = torch.randn_like(out_ref)
    
    out_ref.backward(grad_out)
    out_tr.backward(grad_out)
    
    print("\nBackward pass (vs standard attention):")
    print(f"  dQ max diff: {(Q_ref.grad - Q_tr.grad).abs().max().item():.6f}")
    print(f"  dK max diff: {(K_ref.grad - K_tr.grad).abs().max().item():.6f}")
    print(f"  dV max diff: {(V_ref.grad - V_tr.grad).abs().max().item():.6f}")